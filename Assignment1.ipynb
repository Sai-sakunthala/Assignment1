{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OfhhFzd8a47",
        "outputId": "469f78ea-1da4-4b81-dbc3-b5d026f84095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msai-sakunthala\u001b[0m (\u001b[33msai-sakunthala-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3h6nZ382Jmo"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import wandb\n",
        "import numpy as np\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"Fashion-mnist\", name = \"Images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "XrdilZm-8mPG",
        "outputId": "13c25879-c344-4299-e1f5-64486b9f10cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msai-sakunthala\u001b[0m (\u001b[33msai-sakunthala-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250222_162139-8o75r7iv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sai-sakunthala-indian-institute-of-technology-madras/Fashion-mnist/runs/8o75r7iv' target=\"_blank\">Images</a></strong> to <a href='https://wandb.ai/sai-sakunthala-indian-institute-of-technology-madras/Fashion-mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sai-sakunthala-indian-institute-of-technology-madras/Fashion-mnist' target=\"_blank\">https://wandb.ai/sai-sakunthala-indian-institute-of-technology-madras/Fashion-mnist</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sai-sakunthala-indian-institute-of-technology-madras/Fashion-mnist/runs/8o75r7iv' target=\"_blank\">https://wandb.ai/sai-sakunthala-indian-institute-of-technology-madras/Fashion-mnist/runs/8o75r7iv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sai-sakunthala-indian-institute-of-technology-madras/Fashion-mnist/runs/8o75r7iv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7bd89eeeafd0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "class_names = ['Tshirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'bag', 'Ankleboot']\n",
        "\n",
        "one_per_label = {}\n",
        "for image,label in zip(x_train,y_train):\n",
        "    if label not in one_per_label:\n",
        "        one_per_label[label] = image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjo5eR2QdyIn",
        "outputId": "410183b4-1a42-481f-b364-aa50ca95c193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label, image in one_per_label.items():\n",
        "    wandb.log({\"Images\": [wandb.Image(image, caption=class_names[label])]})"
      ],
      "metadata": {
        "id": "VlCiVcmL9kCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_layer(x):\n",
        "    x = np.array(x)\n",
        "    a,b,c = x.shape\n",
        "    x = x.reshape(a,b*c)\n",
        "    return x\n",
        "\n",
        "def sigmoid(a_x):\n",
        "    h_x = np.zeros(len(a_x))\n",
        "    for i in range(len(a_x)):\n",
        "        h_x[i] = 1/(1+math.exp(-a_x[i]))\n",
        "    return h_x\n",
        "\n",
        "def der_sigmoid(a_x):\n",
        "    del_sig = np.zeros(len(a_x))\n",
        "    for i in range(len(a_x)):\n",
        "        del_sig[i] = a_x[i]*(1-a_x[i])\n",
        "    return del_sig\n",
        "\n",
        "def Relu(a_x):\n",
        "    h_x = np.zeros(len(a_x))\n",
        "    for i in range(len(a_x)):\n",
        "        h_x[i] = max(0,a_x[i])\n",
        "    return h_x\n",
        "\n",
        "def der_Relu(a_x):\n",
        "    del_Relu = np.zeros(len(a_x))\n",
        "    for i in range(len(a_x)):\n",
        "        if a_x[i] > 0:\n",
        "            del_Relu[i] = a_x[i]\n",
        "        else:\n",
        "            del_Relu[i] = 0\n",
        "    return del_Relu\n",
        "\n",
        "def tanh(a_x):\n",
        "    h_x = np.zeros(len(a_x))\n",
        "    for i in range(len(a_x)):\n",
        "        h_x[i] = (math.exp(a_x[i]) - math.exp(-a_x[i]))/(math.exp(a_x[i]) + math.exp(-a_x[i]))\n",
        "    return h_x\n",
        "\n",
        "def der_tanh(a_x):\n",
        "    del_tanh = np.zeros(len(a_x))\n",
        "    for i in range(len(a_x)):\n",
        "        del_tanh[i] = 1 - [(math.exp(a_x[i]) - math.exp(-a_x[i]))/(math.exp(a_x[i]) + math.exp(-a_x[i]))]**2\n",
        "    return del_tanh\n",
        "\n",
        "def softmax(a_x):\n",
        "    h_x = np.zeros(len(a_x))\n",
        "    for i in range(len(a_x)):\n",
        "        h_x[i] = math.exp(a_x[i])\n",
        "    h_x = h_x/np.sum(h_x)\n",
        "    return h_x\n",
        "\n",
        "def der_softmax(a_x):\n",
        "    del_softmax = np.zeros(len(a_x))\n",
        "    for i in range(len(a_x)):\n",
        "        del_softmax[i] = a_x[i]*(1-a_x[i])\n",
        "\n",
        "def initialize_weights(num_neurons):\n",
        "    weights = []\n",
        "    biases = []\n",
        "    for i in range(len(num_neurons) - 1):\n",
        "        W = np.random.randn(num_neurons[i], num_neurons[i+1])\n",
        "        b = np.random.randn(1, num_neurons[i+1])\n",
        "        weights.append(W)\n",
        "        biases.append(b)\n",
        "    return weights, biases\n",
        "\n",
        "def pre_activation(h_x, W, b):\n",
        "    a_x = np.dot(h_x, W) + b\n",
        "    return a_x\n",
        "\n",
        "def loss_function(h_x, y):\n",
        "    idx = np.where(y == 1)\n",
        "    loss = -np.log(h_x[idx])\n",
        "    return loss\n",
        "\n",
        "def forward_pass(x, y, weights, biases, activation_func, n_hidden):\n",
        "    activations = []\n",
        "    pre_activations = []\n",
        "    for i in range(n_hidden+2):\n",
        "        if i == 0:\n",
        "            a_x = pre_activation(x, weights[i], biases[i])\n",
        "            print(a_x)\n",
        "            h_x = activation_func(a_x)\n",
        "            activations.append(h_x)\n",
        "            pre_activations.append(a_x)\n",
        "        elif i == n_hidden + 1:\n",
        "            a_x = pre_activation(h_x, weights[i], biases[i])\n",
        "            h_x = softmax(a_x)\n",
        "            activations.append(h_x)\n",
        "            pre_activations.append(a_x)\n",
        "        else:\n",
        "            a_x = pre_activation(h_x, weights[i], biases[i])\n",
        "            h_x = activation_func(a_x)\n",
        "            activations.append(h_x)\n",
        "            pre_activations.append(a_x)\n",
        "    loss = loss_function(h_x, y)\n",
        "    return np.array(activations), np.array(pre_activations), loss\n",
        "\n",
        "a,b = forward_pass(np.array([[1,1],[0,0],[1,1],[2,2]]), np.array([0,1,0,2]), initialize_weights([2,3,3,2])[0], initialize_weights([2,3,3,2])[1], sigmoid, 2)\n",
        "print(a,b)\n",
        "\n",
        "def one_hot_encode(y, num_classes):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "def back_propagation(activations, pre_activations, weights, biases, y, y_hat, n_hidden, activation_deriv):\n",
        "    del_L_a = {}\n",
        "    del_L_w = {}\n",
        "    del_L_b = {}\n",
        "    del_L_h = {}\n",
        "    for i in range(n_hidden+1, 0, -1):\n",
        "        if i == n_hidden + 1:\n",
        "            del_L_a[i] = -(y - y_hat)\n",
        "        del_L_w[i] = np.dot(activations[i-1].T, del_L_a[i])\n",
        "        del_L_b[i] = del_L_a[i]\n",
        "        del_L_h[i-1] = np.matmul(del_L_a[i], weights[i-1].T)\n",
        "        del_L_a[i-1] = np.multiply(del_L_h[i-1], activation_deriv(pre_activations[i-1]))\n",
        "\n",
        "def Neuralnet(x_train, y_train, n_hidden, n_neurons_hidden, epochs, batch_size, activation):\n",
        "    x_train = input_layer(x_train)\n",
        "    y_train = one_hot_encode(y_train, len(np.unique(y_train)))\n",
        "    features = x_train.shape[1]\n",
        "    classes = len(np.unique(y_train))\n",
        "    num_neurons = [features] + [n_neurons_hidden]*(n_hidden) + [classes]\n",
        "    weights, biases = initialize_weights(num_neurons)\n",
        "    activation_func = {\"sigmoid\": sigmoid, \"tanh\": tanh, \"relu\": Relu}[activation]\n",
        "    activation_deriv = {\"sigmoid\": der_sigmoid, \"tanh\": der_tanh, \"relu\": der_Relu}[activation]\n",
        "    #epochs\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(x_train), batch_size):\n",
        "            x_batch = x_train[i:i + batch_size]\n",
        "            y_batch = y_train[i:i + batch_size]\n",
        "            for x,y in zip(x_batch,y_batch):\n",
        "                activations, pre_activations, loss = forward_pass(x, y, weights, biases, activation_func, n_hidden)\n",
        "\n",
        "#Neuralnet(np.array([[1,1],[0,0],[1,1],[2,2]]), np.array([0,1,0,2]), 2, 3, 10, 2, 'sigmoid')"
      ],
      "metadata": {
        "id": "mNcj8hC1URDj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "30f9eb19-0d3c-4f77-e74e-f52633b62958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.60171371  0.00999735  3.22795799]\n",
            " [-1.54355062  1.12178756  1.39189888]\n",
            " [-1.60171371  0.00999735  3.22795799]\n",
            " [-1.65987681 -1.10179286  5.0640171 ]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "only length-1 arrays can be converted to Python scalars",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c400e8843c8f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_activations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-c400e8843c8f>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(x, y, weights, biases, activation_func, n_hidden)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0ma_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mh_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mpre_activations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-c400e8843c8f>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(a_x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mh_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mh_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mh_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.dot(np.array([[1,2]]).T, np.array([[3,4]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FbXBEYbhAEW",
        "outputId": "0d0d9963-538c-4f39-9d28-2228bd43ee20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 4]\n",
            " [6 8]]\n"
          ]
        }
      ]
    }
  ]
}